{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "mrgan_lib_path = os.path.abspath('../')\n",
    "if mrgan_lib_path not in sys.path:\n",
    "    sys.path.insert(0, mrgan_lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fid.inception import InceptionV3\n",
    "from build_dataset_fid_stats import get_activations, get_stats\n",
    "from fid.fid_score import calculate_frechet_distance\n",
    "from wgan_gp import Generator\n",
    "from wgan_gp_mrr import GeneratorMRRSampler\n",
    "from utils import mask_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gpu()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_gs(mrr, load_gen_path, batch_size=64, latent_dim=128, n_channels=3, wrt='train'):\n",
    "    with np.load(f'../cifar10-{wrt}.npz') as f:\n",
    "        real_features_train = f['features'][:]\n",
    "\n",
    "    # Initialize generator and discriminator\n",
    "    generator = Generator(latent_dim=latent_dim, n_channels=n_channels).to(device=device)\n",
    "    generator.load_state_dict(torch.load(load_gen_path))\n",
    "    generator.eval()\n",
    "    gs = GeneratorMRRSampler(generator, mrr, latent_dim, device,\n",
    "                             real_features_train, bsize=batch_size)\n",
    "    return gs\n",
    "\n",
    "def test(gs, n_samples=10000, wrt='test'):\n",
    "    with np.load(f'../cifar10-{wrt}.npz') as f:\n",
    "        real_mu_test = f['mu'][:]\n",
    "        real_std_test = f['sigma'][:]\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        fake_features_tensor = gs.gen_features(n_instances=10000).detach()\n",
    "    mmd = gs.compute_memorization_distance(fake_features_tensor).cpu().data.numpy().mean()\n",
    "    fid = calculate_frechet_distance(*get_stats(fake_features_tensor.cpu().data.numpy()), \n",
    "                                     real_mu_test, real_std_test)\n",
    "    results = {'mmd': mmd, 'fid': fid}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmd': 0.21070234, 'fid': 49.789739524891786}\n"
     ]
    }
   ],
   "source": [
    "gs = config_gs(0.4, '../images/202010250916/generator_epoch2400.pth')\n",
    "results = test(gs)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results\n",
    "* mrr=0.4 (train): {'mmd': 0.21135798, 'fid': 48.487003033437986}\n",
    "* mrr=0.4 (test): {'mmd': 0.22616123, 'fid': 50.01689172681711}\n",
    "* mrr=0.4 (train-mmd, test-fid): {'mmd': 0.21070234, 'fid': 49.789739524891786}\n",
    "\n",
    "experiments\n",
    "1. examine correlation between mmd and fid generated by train and test (across epochs)\n",
    "2. examine (pre, post) = \\{reject, non_reject\\} X \\{reject, non_reject\\} FID and mmd (wrt fixed testing target)\n",
    "3. ht reject testing FID experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "train_corr = 0.49639633, test_corr = 0.41553263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf2e1dea0784e62a7071b169d32c57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa6125fa7a04b6180e63b8cf66bf4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = np.arange(1000, 2500, 100)\n",
    "mmds, fids = {}, {}\n",
    "for wrt in ['train', 'test']:\n",
    "    mmds[wrt] = []\n",
    "    fids[wrt] = []\n",
    "    for epoch in tqdm(epochs):\n",
    "        gs = config_gs(0, f'../images/202010250916/generator_epoch{epoch}.pth')\n",
    "        result = test(gs, wrt=wrt)\n",
    "        \n",
    "        mmds[wrt].append(result['mmd'])\n",
    "        fids[wrt].append(result['fid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.49639633]\n",
      " [0.49639633 1.        ]]\n",
      "[[1.         0.41553263]\n",
      " [0.41553263 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_coef = np.corrcoef(mmds['train'], fids['train'])\n",
    "test_coef = np.corrcoef(mmds['test'], fids['test'])\n",
    "print(train_coef)\n",
    "print(test_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_gen_paths = {\n",
    "    '0': '../images/202010250916/generator_epoch2000.pth',\n",
    "    '0.2': '../images/202010300040/generator_epoch2000.pth',\n",
    "    '0.3': '../images/202010300039/generator_epoch2000.pth',\n",
    "    '0.4': '../images/202010300038/generator_epoch2000.pth',\n",
    "}\n",
    "\n",
    "def repeat_and_accu(gs, wrt='test', n=5):\n",
    "    results = {}\n",
    "    for _ in range(n):\n",
    "        result = test(gs, wrt=wrt)\n",
    "        for k in result.keys():\n",
    "            if k not in results:\n",
    "                results[k] = []\n",
    "            results[k].append(result[k])\n",
    "    return {k: {'mu': np.mean(v), 'std': np.std(v)} \n",
    "            for k, v in results.items()}\n",
    "\n",
    "def plot(mrr, results, save_plot=False):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=[10, 5])\n",
    "    for ax, metric in zip(axs, ['fid', 'mmd']):\n",
    "        for mode, dx in [('train', -0.4), ('test', 0.4)]:\n",
    "            r = results[mrr][mode]\n",
    "            labels = list(r.keys())\n",
    "            mus = [r[l][metric]['mu'] for l in labels]\n",
    "            stds = [r[l][metric]['std'] for l in labels]\n",
    "            px = np.arange(len(labels)) * 3\n",
    "\n",
    "            ax.bar(px + dx, mus, yerr=stds, label=mode)\n",
    "            ax.set_xticks(px)\n",
    "            ax.set_xticklabels(labels)\n",
    "            ax.set_title(metric)\n",
    "            ax.set_ylim([0, max(mus) * 1.25])\n",
    "        ax.legend()\n",
    "    if save_plot:\n",
    "        plt.savefig(f'pre-post-reject_mrr={mrr}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### experiment on mrr=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = 0.4\n",
    "results_ = {}\n",
    "\n",
    "gss = {\n",
    "    'nn': config_gs(0, pretrained_gen_paths['0']),\n",
    "    'nr': config_gs(mrr, pretrained_gen_paths['0']),\n",
    "    'rn': config_gs(0, pretrained_gen_paths[str(mrr)]),\n",
    "    'rr': config_gs(mrr, pretrained_gen_paths[str(mrr)]),\n",
    "}\n",
    "\n",
    "for mode in ['train', 'test']:\n",
    "    results_[mode] = {}\n",
    "    for var, gs in gss.items():\n",
    "        results_[mode][var] = repeat_and_accu(gs)\n",
    "\n",
    "results[mrr] = results_\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(0.4, results, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = 0.3\n",
    "results_ = {}\n",
    "\n",
    "gss = {\n",
    "    'nn': config_gs(0, pretrained_gen_paths['0']),\n",
    "    'nr': config_gs(mrr, pretrained_gen_paths['0']),\n",
    "    'rn': config_gs(0, pretrained_gen_paths[str(mrr)]),\n",
    "    'rr': config_gs(mrr, pretrained_gen_paths[str(mrr)]),\n",
    "}\n",
    "\n",
    "for mode in ['train', 'test']:\n",
    "    results_[mode] = {}\n",
    "    for var, gs in gss.items():\n",
    "        results_[mode][var] = repeat_and_accu(gs)\n",
    "\n",
    "results[mrr] = results_\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(0.3, results, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\r\n",
      "import os\r\n",
      "import numpy as np\r\n",
      "import math\r\n",
      "import sys\r\n",
      "from datetime import datetime\r\n",
      "import time\r\n",
      "import yaml\r\n",
      "\r\n",
      "import torchvision.transforms as transforms\r\n",
      "from torchvision.utils import save_image, make_grid\r\n",
      "\r\n",
      "from torch.utils.data import DataLoader\r\n",
      "from torchvision import datasets\r\n",
      "from torch.autograd import Variable\r\n",
      "\r\n",
      "import torch.nn as nn\r\n",
      "import torch.nn.functional as F\r\n",
      "import torch.autograd as autograd\r\n",
      "import torch\r\n",
      "\r\n",
      "from tensorboardX import SummaryWriter\r\n",
      "from torchsummary import summary\r\n",
      "\r\n",
      "from fid.inception import InceptionV3\r\n",
      "from fid.fid_score import calculate_frechet_distance\r\n",
      "from build_dataset_fid_stats import get_stats\r\n",
      "from utils import mask_gpu, seed_everything\r\n",
      "from wgan_gp import Generator, Discriminator, GeneratorMRSampler, compute_gradient_penalty\r\n",
      "\r\n",
      "class GeneratorMRRSampler(GeneratorMRSampler):\r\n",
      "    def __init__(self, generator, mrr, latent_dim, device, real_features, \r\n",
      "                 proj_model=None, bsize=64, normalize=True):\r\n",
      "        self.mrr = mrr\r\n",
      "        self.eff_bsize = np.ceil(bsize / (1 - self.mrr)).astype(np.int)\r\n",
      "\r\n",
      "        super(GeneratorMRRSampler, self).__init__(\r\n",
      "                generator=generator, latent_dim=latent_dim, device=device, \r\n",
      "                real_features=real_features, proj_model=proj_model, \r\n",
      "                bsize=bsize, normalize=normalize)\r\n",
      "\r\n",
      "        self.accu_mrt = 0\r\n",
      "        self.accu_steps = 0\r\n",
      "\r\n",
      "    def reset_running_stats(self):\r\n",
      "        self.accu_mrt = 0\r\n",
      "        self.accu_steps = 0\r\n",
      "\r\n",
      "    def get_mrt(self):\r\n",
      "        if self.accu_steps == 0:\r\n",
      "            return 0\r\n",
      "        else:\r\n",
      "            return self.accu_mrt / self.accu_steps\r\n",
      "\r\n",
      "    def __next__(self):\r\n",
      "        if self.mrr == 0:\r\n",
      "            z = super(GeneratorMRRSampler, self).__next__()\r\n",
      "\r\n",
      "            self.accu_steps += 1\r\n",
      "        else:\r\n",
      "            with torch.no_grad():\r\n",
      "                z = Variable(torch.from_numpy(np.random.normal(0, 1, (self.eff_bsize, self.latent_dim))).float()).to(self.device)\r\n",
      "                fake_features_tensor = self._gen_features(z)\r\n",
      "\r\n",
      "                min_d = self.compute_memorization_distance(fake_features_tensor)\r\n",
      "                mrt = torch.topk(min_d, self.bsize).values.min()\r\n",
      "                # mrt = (min_d[sorted_indices[self.bsize - 1]].item() + min_d[sorted_indices[self.bsize]].item()) / 2\r\n",
      "\r\n",
      "                mr_mask = min_d >= mrt\r\n",
      "                z = torch.masked_select(z, mr_mask.view(-1, 1)).view(-1, self.latent_dim)\r\n",
      "\r\n",
      "                self.accu_mrt += mrt\r\n",
      "                self.accu_steps += 1\r\n",
      "        return z\r\n",
      "\r\n",
      "def main():\r\n",
      "\r\n",
      "    seed_everything()\r\n",
      "    mask_gpu()\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument('--verbose', action='store_true')\r\n",
      "    parser.add_argument('--test', action='store_true')\r\n",
      "    parser.add_argument(\"--n_epochs\", type=int, default=2500, help=\"number of epochs of training\")\r\n",
      "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\r\n",
      "    parser.add_argument(\"--lr\", type=float, default=0.00005, help=\"adam: learning rate\")\r\n",
      "    parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\r\n",
      "    parser.add_argument(\"--b2\", type=float, default=0.9, help=\"adam: decay of first order momentum of gradient\")\r\n",
      "    parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\r\n",
      "    parser.add_argument(\"--latent_dim\", type=int, default=128, help=\"dimensionality of the latent space\")\r\n",
      "    parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\r\n",
      "    parser.add_argument(\"--n_channels\", type=int, default=3, help=\"number of image channels\")\r\n",
      "    parser.add_argument(\"--n_critic\", type=int, default=5, help=\"number of training steps for discriminator per iter\")\r\n",
      "    parser.add_argument(\"--gp\", type=float, default=10., help=\"Loss weight for gradient penalty\")\r\n",
      "    parser.add_argument(\"--num_samples\", type=int, default=10000, help=\"number of samples\")\r\n",
      "    parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval betwen image samples\")\r\n",
      "    parser.add_argument(\"--metric_interval\", type=int, default=10, help=\"interval betwen metrics evaluations\")\r\n",
      "    parser.add_argument(\"--save_model_interval\", type=int, default=100, help=\"interval betwen model saves\")\r\n",
      "    parser.add_argument(\"--print_interval\", type=int, default=1, help=\"interval betwen printing training stats\")\r\n",
      "    parser.add_argument(\"--mrr\", type=float, default=0, help=\"memorization rejection rate, percentage per batch to reject via memorization distance.\")\r\n",
      "    parser.add_argument(\"--epoch_start\", type=int, default=0, help=\"the index of the beginning of training, usually set when loaded from pretrain model\")\r\n",
      "    parser.add_argument(\"--load_gen_path\", default=None, help=\"path to load the generator state_dict\")\r\n",
      "    parser.add_argument(\"--load_dis_path\", default=None, help=\"path to load the discriminator state_dict\")\r\n",
      "    parser.add_argument(\"--path_path\", default='path.yml', help=\"path to configuration for training related file paths and dirs\")\r\n",
      "    opt = parser.parse_args()\r\n",
      "\r\n",
      "    opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
      "    with open(opt.path_path) as f:\r\n",
      "        opt.paths = yaml.load(f, Loader=yaml.FullLoader)\r\n",
      "    print(opt)\r\n",
      "\r\n",
      "    # load prep train features\r\n",
      "    with np.load(opt.paths['prep_dataset_path']) as f:\r\n",
      "        real_features = f['features'][:]\r\n",
      "        real_mu = f['mu'][:]\r\n",
      "        real_sigma = f['sigma'][:]\r\n",
      "\r\n",
      "    # Initialize generator and discriminator\r\n",
      "    generator = Generator(latent_dim=opt.latent_dim, n_channels=opt.n_channels).to(device=opt.device)\r\n",
      "    discriminator = Discriminator(latent_dim=opt.latent_dim, n_channels=opt.n_channels).to(device=opt.device)\r\n",
      "    gs = GeneratorMRRSampler(generator, opt.mrr, opt.latent_dim, opt.device,\r\n",
      "                             real_features, bsize=opt.batch_size)\r\n",
      "\r\n",
      "    if opt.load_gen_path is not None:\r\n",
      "        generator.load_state_dict(torch.load(opt.load_gen_path))\r\n",
      "        print(f\"Loading {opt.load_gen_path} as generator...\")\r\n",
      "    if opt.load_dis_path is not None:\r\n",
      "        discriminator.load_state_dict(torch.load(opt.load_dis_path))\r\n",
      "        print(f\"Loading {opt.load_dis_path} as discriminator...\")\r\n",
      "\r\n",
      "    if opt.verbose:\r\n",
      "        summary(generator, input_size=(opt.latent_dim,))\r\n",
      "        summary(discriminator, input_size=(opt.n_channels, opt.img_size, opt.img_size))\r\n",
      "\r\n",
      "    # Configure data loader\r\n",
      "    data_dir = opt.paths['data_dir']\r\n",
      "    os.makedirs(data_dir, exist_ok=True)\r\n",
      "    dataloader = torch.utils.data.DataLoader(\r\n",
      "        datasets.CIFAR10(\r\n",
      "            data_dir,\r\n",
      "            train=True,\r\n",
      "            download=True,\r\n",
      "            transform=transforms.Compose(\r\n",
      "                [transforms.ToTensor(), transforms.Normalize([0.5] * opt.n_channels, [0.5] * opt.n_channels)]\r\n",
      "            ),\r\n",
      "        ),\r\n",
      "        batch_size=opt.batch_size,\r\n",
      "        shuffle=True\r\n",
      "    )\r\n",
      "\r\n",
      "    # Optimizers\r\n",
      "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\r\n",
      "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\r\n",
      "\r\n",
      "    if not opt.test:\r\n",
      "        # prepare save directory\r\n",
      "        timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d%H%M')\r\n",
      "        log_dir = os.path.join(opt.paths['img_dir'], timestamp)\r\n",
      "        os.makedirs(log_dir)\r\n",
      "        print(f\"store in directory {log_dir}\")\r\n",
      "        # dump options config\r\n",
      "        with open(os.path.join(log_dir, 'opt.yml'), 'w') as f:\r\n",
      "            yaml.dump(opt, f, default_flow_style=False)\r\n",
      "        # prepare writer\r\n",
      "        writer = SummaryWriter(logdir=log_dir)\r\n",
      "\r\n",
      "    for epoch in range(opt.epoch_start + 1, opt.n_epochs + 1):\r\n",
      "\r\n",
      "        generator.train()\r\n",
      "        gs.reset_running_stats()\r\n",
      "\r\n",
      "        for i, (imgs, _) in enumerate(dataloader):\r\n",
      "\r\n",
      "            optimizer_D.zero_grad()\r\n",
      "\r\n",
      "            real_imgs = Variable(imgs).to(opt.device)\r\n",
      "            z = next(gs)[:real_imgs.shape[0]]\r\n",
      "            fake_imgs = generator(z)\r\n",
      "\r\n",
      "            if real_imgs.shape != fake_imgs.shape:\r\n",
      "                raise Exception(f\"real_imgs has shape {real_imgs.shape} but fake_imgs has shape {fake_imgs.shape}\")\r\n",
      "\r\n",
      "            real_validity = discriminator(real_imgs)\r\n",
      "            fake_validity = discriminator(fake_imgs)\r\n",
      "            gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data, device=opt.device)\r\n",
      "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + opt.gp * gradient_penalty\r\n",
      "\r\n",
      "            d_loss.backward()\r\n",
      "            optimizer_D.step()\r\n",
      "\r\n",
      "            optimizer_G.zero_grad()\r\n",
      "\r\n",
      "            if i % opt.n_critic == 0:\r\n",
      "\r\n",
      "                fake_imgs = generator(z)\r\n",
      "                fake_validity = discriminator(fake_imgs)\r\n",
      "                g_loss = -torch.mean(fake_validity)\r\n",
      "\r\n",
      "                g_loss.backward()\r\n",
      "                optimizer_G.step()\r\n",
      "\r\n",
      "        generator.eval()\r\n",
      "\r\n",
      "        if not opt.test:\r\n",
      "            writer.add_scalar('loss/d_loss', d_loss.item(), epoch)\r\n",
      "            writer.add_scalar('loss/g_loss', g_loss.item(), epoch)\r\n",
      "\r\n",
      "            writer.add_scalar('stats/mrt', gs.get_mrt(), epoch)\r\n",
      "\r\n",
      "        if epoch % opt.print_interval == 0 or opt.test:\r\n",
      "            print_str = f\"{datetime.now().strftime('%Y/%m/%d %H:%M:%S')} [Epoch {epoch}/{opt.n_epochs}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [mrt: {gs.get_mrt()}]\"\r\n",
      "            print(print_str)\r\n",
      "\r\n",
      "        if epoch % opt.sample_interval == 0 and not opt.test:\r\n",
      "            img_fname = os.path.join(log_dir, f\"{epoch}.png\")\r\n",
      "            save_image(fake_imgs.data[:36], img_fname, nrow=6, normalize=True)\r\n",
      "\r\n",
      "        if epoch % opt.metric_interval == 0 or opt.test:\r\n",
      "\r\n",
      "            with torch.no_grad():\r\n",
      "                fake_features_tensor = gs.gen_features(n_instances=10000).detach()\r\n",
      "\r\n",
      "            mds = gs.compute_memorization_distance(fake_features_tensor).cpu().data.numpy()\r\n",
      "            mmd = np.mean(mds)\r\n",
      "            fake_mu, fake_sigma = get_stats(fake_features_tensor.cpu().data.numpy())\r\n",
      "            fid = calculate_frechet_distance(fake_mu, fake_sigma, real_mu, real_sigma) # numpy input\r\n",
      "\r\n",
      "            if not opt.test:\r\n",
      "                writer.add_scalar('metric/fid', fid, epoch)\r\n",
      "                writer.add_scalar('metric/mmd', mmd, epoch)\r\n",
      "\r\n",
      "            print(f\"{datetime.now().strftime('%Y/%m/%d %H:%M:%S')} [fid: {fid}] [mmd: {mmd}]\")\r\n",
      "\r\n",
      "        if epoch % opt.save_model_interval == 0 and epoch > 1 and not opt.test:\r\n",
      "            torch.save(generator.state_dict(), os.path.join(log_dir, f\"generator_epoch{epoch}.pth\"))\r\n",
      "            torch.save(discriminator.state_dict(), os.path.join(log_dir, f\"discriminator_epoch{epoch}.pth\"))\r\n",
      "\r\n",
      "    if not opt.test:\r\n",
      "        # final save\r\n",
      "        torch.save(generator.state_dict(), os.path.join(log_dir, \"generator.pth\"))\r\n",
      "        torch.save(discriminator.state_dict(), os.path.join(log_dir, \"discriminator.pth\"))\r\n",
      "\r\n",
      "        export_json = os.path.join(log_dir, \"all_scalars.json\")\r\n",
      "        writer.export_scalars_to_json(export_json)\r\n",
      "        writer.close()\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "%cat ../wgan_gp_mrr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
